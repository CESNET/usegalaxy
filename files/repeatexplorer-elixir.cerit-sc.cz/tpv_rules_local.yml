tools:
  .*/trimmomatic/.*:
    rules:
      - id: no_singularity
        if: |
          # versions without singularity container available
          no_container = {
              '0.39+galaxy0',
          }
          any(helpers.tool_version_eq(tool, version) for version in no_container)
        scheduling:
          require:
            - conda

  # DEMON: All Novak's tools (except 2) are not properly containerized, therefore, they need conda to deal with dependences
  .*/petr-novak/.*:
    cores: 2
    mem: 10
    context:
      scratch: 15
    scheduling:
      require:
        - conda

  # DANTE_TIR toolset: https://toolshed.g2.bx.psu.edu/repos/petr-novak/dante_tir
  toolshed.g2.bx.psu.edu/repos/petr-novak/dante_tir/.*:
    cores: 20
    mem: 32
    context:
      walltime: 48

  # DANTE toolset: https://toolshed.g2.bx.psu.edu/repos/petr-novak/dante
  toolshed.g2.bx.psu.edu/repos/petr-novak/dante/domains_filter/.*:
    mem: 25
  toolshed.g2.bx.psu.edu/repos/petr-novak/dante/gff_to_tabular/.*:
    mem: 25
  toolshed.g2.bx.psu.edu/repos/petr-novak/dante/gff_summary/.*:
    mem: 25
  toolshed.g2.bx.psu.edu/repos/petr-novak/dante/domains_extract/.*:
    mem: 25
  toolshed.g2.bx.psu.edu/repos/petr-novak/dante/dante/.*:
    cores: 32
    mem: 25
    context:
      walltime: 336

  # TideCluster tools http://toolshed.g2.bx.psu.edu/repos/petr-novak/tidecluster
  toolshed.g2.bx.psu.edu/repos/petr-novak/tidecluster/tidecluster_annotation/.*:
    cores: 16
    mem: 24
  toolshed.g2.bx.psu.edu/repos/petr-novak/tidecluster/tc_reannotate/.*:
    cores: 32
    mem: 50
    context:
      walltime: 96
  toolshed.g2.bx.psu.edu/repos/petr-novak/tidecluster/tidecluster/.*:
    cores: 16
    mem: 64
    context:
      scratch: 150
      walltime: 336

  # repeat_annotation_pipeline tools http://toolshed.g2.bx.psu.edu/repos/petr-novak/repeat_annotation_pipeline3
#  toolshed.g2.bx.psu.edu/repos/petr-novak/repeat_annotation_pipeline3/extract_re_contigs/.*:
#    cores: 2
#    mem: 10
#    context:
#      scratch: 15
#  toolshed.g2.bx.psu.edu/repos/petr-novak/repeat_annotation_pipeline3/compare_gff/.*:
#    cores: 2
#    mem: 10
#    context:
#      scratch: 15
#  toolshed.g2.bx.psu.edu/repos/petr-novak/repeat_annotation_pipeline3/summarize_gff_by_attribute/.*:
#    cores: 2
#    mem: 10
#    context:
#      scratch: 15
#  toolshed.g2.bx.psu.edu/repos/petr-novak/repeat_annotation_pipeline3/annotate_contigs/.*:
#    cores: 2
#    mem: 10
#    context:
#      scratch: 15
  toolshed.g2.bx.psu.edu/repos/petr-novak/repeat_annotation_pipeline3/repeat_annotate/.*:
    cores: 32
    mem: 50
    context:
      scratch: 50
      walltime: 96

  # re_utils tools https://toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/RMsearch2/.*:
    cores: 16
    mem: 32
    context:
      scratch: 50
      walltime: 96
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/chip_seq_ratio_1/.*:
    cores: 16
    mem: 32
    context:
      scratch: 50
      walltime: 48
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/rename_sequences/.*:
    context:
      scratch: 50
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/pairScan/.*:
    context:
      scratch: 50
      walltime: 48
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/single_fastq_filtering/.*:
    cores: 6
    context:
      scratch: 50
      walltime: 24
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/fasta_affixer/.*:
    context:
      scratch: 50
#  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/sampler/.*:
#    context:
#      scratch: 15
#  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/plot_comparative/.*:
#    context:
#      scratch: 15
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/extract_var_files_from_re/.*:
    context:
      scratch: 50
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/summarize_annotation/.*:
    context:
      scratch: 50
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/names_affixer/.*:
    context:
      scratch: 50
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/cluster_table2krona_format/.*:
    context:
      scratch: 50
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/fasta_input/.*:
    context:
      scratch: 50
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/fasta_interlacer/.*:
    context:
      scratch: 50
  toolshed.g2.bx.psu.edu/repos/petr-novak/re_utils/paired_fastq_filtering/.*:
#    mem: 10 #DEMON: old setting but there was job which used 78GB; the best would be to scale to input size
    mem: 50
    context:
      scratch: 50
#      walltime: 24 #DEMON: used to be 24h but if input is very big it could take more time, would be great to scale it to input size
      walltime: 48

  # DANTE_ltr tools http://toolshed.g2.bx.psu.edu/repos/petr-novak/dante_ltr
#  toolshed.g2.bx.psu.edu/repos/petr-novak/dante_ltr/dante_ltr_summary/.*:
#    cores: 2
#    mem: 10
#    context:
#      scratch: 15
  toolshed.g2.bx.psu.edu/repos/petr-novak/dante_ltr/clean_dante_ltr/.*:
    cores: 32
    mem: 64
    context:
      scratch: 64
      walltime: 168
  toolshed.g2.bx.psu.edu/repos/petr-novak/dante_ltr/dante_ltr_search/.*:
    cores: 32
    mem: 64
    context:
      scratch: 64
      walltime: 168
  toolshed.g2.bx.psu.edu/repos/petr-novak/dante_ltr/dante_ltr_to_library/.*:
    cores: 32
    mem: 64
    context:
      scratch: 64
      walltime: 168
  
  # ReapeatExplorer tools http://toolshed.g2.bx.psu.edu/repos/petr-novak/repeatexplorer2_testing
  toolshed.g2.bx.psu.edu/repos/petr-novak/repeatexplorer2_testing/repeatexplorer2/.*:
    cores: 10
    mem: 4
    context:
      scratch: 50
      walltime: 48
    scheduling:
      reject:
        - conda
      require:
        - singularity
    container_resolvers:
    -   type: cached_explicit_singularity
        cache_directory: "$SINGULARITY_CACHEDIR"
    -   type: explicit_singularity
    -   type: cached_mulled_singularity
        cache_directory: "$SINGULARITY_CACHEDIR"
    -   auto_install: true
        type: mulled_singularity
    -   auto_install: false
        cache_directory: /mnt/galaxy-re/singularity/mulled
        type: build_mulled_singularity
    params:
      singularity_default_container_id: "/storage/brno11-elixir/home/galaxyelixir/pulsar-re/files/singularity_cache/cache/library/sha256.660dda926394f3db2400f7800e064cf731c75566853cac43a30be44e3b5f5d73"
    env:
      SINGULARITY_CACHEDIR: "/storage/brno11-elixir/home/galaxyelixir/pulsar-re/files/singularity_cache"
    rules:
      - id: queue_definition_by_parameter
        if: |
          param_dict = job.get_param_values(app) # get job input parameters as dictionary
          'queue_definition' in param_dict and 'queue_specification' in param_dict['queue_definition']
        cores: |
          import re
          int(re.search(r'ncpus=(\d)+', job.get_param_values(app)['queue_definition']['queue_specification']).group(0).split('=')[1])
        mem: |
          import re
          int(re.search(r'mem=(\d)+', job.get_param_values(app)['queue_definition']['queue_specification']).group(0).split('=')[1])
        context:
          scratch: |
            import re
            int(re.search(r'scratch_local=(\d)+', job.get_param_values(app)['queue_definition']['queue_specification']).group(0).split('=')[1])
          walltime: |
            import re
            int(re.search(r'walltime=(\d)+', job.get_param_values(app)['queue_definition']['queue_specification']).group(0).split('=')[1])
      - id: basic_fast_queue_selected
        if: |
          param_dict = job.get_param_values(app) # get job input parameters as dictionary
          'queue_select' in param_dict and param_dict['queue_select'].startswith('basic_fast_queue')
        cores: 10
        mem: 16
        context:
          scratch: 50
          walltime: 48
      - id: long_slow_queue_selected
        if: |
          param_dict = job.get_param_values(app) # get job input parameters as dictionary
          'queue_select' in param_dict and param_dict['queue_select'].startswith('long_slow_queue')
        cores: 16
        mem: 64
        context:
          scratch: 50
          walltime: 336
      - id: extra_long_slow_queue_selected
        if: |
          param_dict = job.get_param_values(app) # get job input parameters as dictionary
          'queue_select' in param_dict and param_dict['queue_select'].startswith('extra_long_slow_queue')
        cores: 16
        mem: 64
        context:
          scratch: 50
          walltime: 720

  toolshed.g2.bx.psu.edu/repos/petr-novak/repeatexplorer2_testing/tarean/.*:
    inherits: toolshed.g2.bx.psu.edu/repos/petr-novak/repeatexplorer2_testing/repeatexplorer2/.*
