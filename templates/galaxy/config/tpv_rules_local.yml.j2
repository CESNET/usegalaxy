global:
  default_inherits: default

tools:
  default:
#    abstract: true
    cores: 1
    mem: cores * 4
    env:
    - name: GALAXY_SLOTS
      value: "{cores}"
    - name:  GALAXY_MEMORY_MB
      value: "{int(mem)*1000}"
    params: {}
    context:
      walltime: 24
      scratch: 50
    scheduling:
      require:
        - pulsar
        - singularity
      reject:
        - offline
    rules: []
    rank: |
      helpers.weighted_random_sampling(candidate_destinations)

  .*/recetox_aplcms_remove_noise/.*:
    cores: 1
    mem: 10

  .*testing.*:
    cores: 1
    mem: 1
    context:
      walltime: 1
    rules:
      - id: admin_only_testing_tool
        if: |
          # Only allow the tool to be executed if the user is an admin
          admin_users = app.config.admin_users
          # last line in block must evaluate to a value - which determines whether the TPV if conditional matches or not
          not user or user.email not in admin_users
        fail: Unauthorized. Only admins can execute this tool.

      - id: resource_params_defined
        if: |
          param_dict = job.get_param_values(app)
          param_dict.get('__job_resource', {}).get('__job_resource__select') == 'yes'
        cores: int(job.get_param_values(app)['__job_resource']['cores'])
        context:
           walltime: "{int(job.get_param_values(app)['__job_resource']['time'])}"

  .*/fastqc/.*:
    cores: 1 
    context:
      walltime: 2
    scheduling:
      require:
      - tesp
      - pulsar
      - singularity

#roles:
#  training.*:
#    max_cores: 2
#    max_mem: max_cores * 4  # TODO check multiplier
#    scheduling:
#      require:
#        - pulsar
#        - training

destinations:
  tpv_local:
    runner: local_runner
    max_accepted_cores: 1
    max_accepted_mem: 4
    max_accepted_gpus: 0
    params:
      tmp_dir: true
    scheduling:
      require:
        - local
      reject:
        - pulsar
        - singularity
  tpv_singularity:
    runner: local_runner
    max_accepted_cores: 1
    max_accepted_mem: 4
    max_accepted_gpus: 0
    params:
      require_container: true
      singularity_enabled: true
      singularity_default_container_id: "/cvmfs/singularity.galaxyproject.org/all/python:3.8.3"
    env:
      # Ensuring a consistent collation environment is good for reproducibility.
      LC_ALL: C
      # The cache directory holds the docker containers that get converted
      SINGULARITY_CACHEDIR: "{{ singularity_local_cache_dir }}"
      # Singularity uses a temporary directory to build the squashfs filesystem
      SINGULARITY_TMPDIR: "/tmp"
    scheduling:
      require:
        - local
      prefer:
        - singularity
      reject:
        - pulsar

  tpv_pulsar:
    runner: pulsar_runner
    max_accepted_cores: 128
    max_accepted_mem: 512
    max_accepted_gpus: 0
    max_cores: 32
    max_mem: 160
    max_gpus: 0
    params:
      default_file_action: remote_transfer
      transport: curl
      dependency_resolution: remote
      jobs_directory: "{{ pulsar_staging_dir }}"
      persistence_directory: "{{ pulsar_persistence_dir }}"
      remote_metadata: false
      rewrite_parameters: true
      outputs_to_working_directory: false
      submit_native_specification: "-l select=1:ncpus={int(cores)}:mem={int(mem)}gb:scratch_local={scratch}gb -l walltime={walltime}:00:00 -q galaxyumsa@pbs-m1.metacentrum.cz -N pulsar_umsa_j{job.id}__{tool.id if '/' not in tool.id else tool.id.split('/')[-2]+'_v'+tool.id.split('/')[-1]}__{user.username if user and hasattr(user, 'username') else 'anonymous'}"
      require_container: true
      singularity_enabled: true
      singularity_volumes: "$job_directory:rw,$tool_directory:ro,$job_directory/outputs:rw,$working_directory:rw,/cvmfs/data.galaxyproject.org:ro,$SCRATCHDIR:rw,/storage/brno11-elixir/home/galaxyumsa:/home/galaxyumsa:rw"
      singularity_default_container_id: "/cvmfs/singularity.galaxyproject.org/all/python:3.8.3"
    env:
      LC_ALL: C
      TMPDIR: $SCRATCHDIR
      TMP: $SCRATCHDIR
      TEMP: $SCRATCHDIR 
      SINGULARITY_CACHEDIR: "/cvmfs/singularity.galaxyproject.org/all/"
      SINGULARITY_TMPDIR: "$SCRATCHDIR"
      XDG_CACHE_HOME: "$SCRATCHDIR"
    scheduling:
      require:
      - pulsar
      - singularity

  tpv_tesp:
    runner: tes_runner
    max_accepted_cores: 128
    max_accepted_mem: 512
    max_accepted_gpus: 0
    max_cores: 16
    max_mem: 64
    max_gpus: 0
    params:
      tes_master_addr: http://pulsar-umsa.grid.cesnet.cz:8080
      rewrite_parameters: true
      require_container: true
      singularity_enabled: true
      singularity_volumes: "$job_directory:rw,$tool_directory:ro,$job_directory/outputs:rw,$working_directory:rw,/cvmfs/data.galaxyproject.org:ro,$SCRATCHDIR:rw"
      singularity_default_container_id: "/cvmfs/singularity.galaxyproject.org/all/python:3.8.3"
      submit_native_specification: "-l select=1:ncpus={int(cores)}:mem={int(mem)}gb:scratch_local={scratch}gb -l walltime={walltime}:00:00 -q galaxyumsa@pbs-m1.metacentrum.cz -N pulsar_umsa_j{job.id}__{tool.id if '/' not in tool.id else tool.id.split('/')[-2]+'_v'+tool.id.split('/')[-1]}__{user.username if user and hasattr(user, 'username') else 'anonymous'}"
    env:
    - name:  SINGULARITY_CACHEDIR
      value: "/auto/brno11-elixir/home/galaxyumsa/.singularity"
    - name:  SINGULARITY_TMPDIR
      value: "$SCRATCHDIR"
    - name:  XDG_CACHE_HOME
      value: "$SCRATCHDIR"
    - name:  LC_ALL
      value: C
    - name: TMPDIR
      value: $SCRATCHDIR
    - name: TMP
      value: $SCRATCHDIR
    - name: TEMP
      value: $SCRATCHDIR
    scheduling:
      require:
        - tesp
        - pulsar
        - singularity
    
#  pulsar_gpu:
#    runner: pulsar_gpu_runner
#    max_accepted_cores: 128
#    max_accepted_mem: 512
#    max_accepted_gpus: 2
#    max_cores: 16
#    max_mem: 64
#    max_gpus: 1
#    params:
#      default_file_action: remote_transfer
#      transport: curl
#      dependency_resolution: remote
#      jobs_directory: "/auto/brno11-elixir/home/galaxyumsa/pulsar-umsa/files/staging"
#      persistence_directory: "/opt/pulsar/files/persistent"
#      remote_metadata: false
#      rewrite_parameters: true
#      outputs_to_working_directory: false
#      singularity_enabled: true
#      singularity_run_extra_arguments: '--nv'
#      singularity_volumes: '$job_directory:ro,$tool_directory:ro,$job_directory/outputs:rw,$working_directory:rw,$SCRATCHDIR,$ALPHAFOLD_DB:/data/2.3:ro'
#    env:
#      # The cache directory holds the docker containers that get converted
#      - name: SINGULARITY_CACHEDIR
#        value: "/storage/praha5-elixir/home/galaxyeu/singularity/cache"
#      - name: APPTAINER_CACHEDIR
#        value: "/storage/praha5-elixir/home/galaxyeu/singularity/cache"
#      # Singularity uses a temporary directory to build the squashfs filesystem
#      - name: SINGULARITY_TMPDIR
#        value: "/storage/praha5-elixir/home/galaxyeu/singularity/tmp" 
#      - name: APPTAINER_TMPDIR
#        value: "/storage/praha5-elixir/home/galaxyeu/singularity/tmp"
#      # Alphafold specific variables
#      - name: ALPHAFOLD_DB
#        value: "/storage/brno11-elixir/projects/alphafold/alphafold.db-2.3.1"
#      # Default variables
#      - name: TMPDIR
#        value: "$SCRATCHDIR"
#      - name: TMP
#        value: "$SCRATCHDIR"
#      - name: TEMP
#        value: "$SCRATCHDIR"
#      # Ensuring a consistent collation environment is good for reproducibility.
#      - name: LC_ALL
#        value: C
#    scheduling:
#      require:
#        - pulsar
#        - gpu

#  pulsar-training:
#    inherits: pulsar
#    runner: pulsar_runner
#    max_accepted_cores: 12
#    max_accepted_mem: 120
#    max_cores: 2 # Limit the cores
#    max_mem: 8 # Limit the memory
#    params:
#      native_specification: --nodes=1 --ntasks=1 --mem={round(mem*1024)} --cpus-per-task={cores} --time=00:30:00
#    scheduling:
#      require:
#        - pulsar
#        - training
